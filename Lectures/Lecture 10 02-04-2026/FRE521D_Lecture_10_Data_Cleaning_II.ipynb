{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRE 521D: Data Analytics in Climate, Food and Environment\n",
    "## Lecture 10: Data Cleaning II - Outliers, Validation, and Quality Scoring\n",
    "\n",
    "**Date:** Wednesday, February 4, 2026  \n",
    "**Instructor:** Asif Ahmed Neloy  \n",
    "**Program:** UBC Master of Food and Resource Economics\n",
    "\n",
    "---\n",
    "\n",
    "### Today's Agenda\n",
    "\n",
    "1. Understanding Outliers\n",
    "2. Statistical Outlier Detection (IQR Method)\n",
    "3. Z-Score Based Detection\n",
    "4. Domain-Based Outlier Rules\n",
    "5. Missing Value Patterns and Handling\n",
    "6. Validation Rules and Constraints\n",
    "7. Referential Integrity Checks\n",
    "8. Data Quality Scoring Framework\n",
    "9. Automated Quality Reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you will be able to:\n",
    "\n",
    "1. Distinguish between legitimate extreme values and data errors\n",
    "2. Apply IQR and Z-score methods to detect statistical outliers\n",
    "3. Create domain-specific validation rules based on business logic\n",
    "4. Identify missing value patterns (MCAR, MAR, MNAR)\n",
    "5. Implement referential integrity checks between tables\n",
    "6. Build a data quality scoring system\n",
    "7. Generate automated quality reports for production pipelines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.1\n",
      "NumPy version: 2.1.3\n",
      "Current time: 2026-02-02 09:57:59\n",
      "Ready for Data Cleaning II!\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Ready for Data Cleaning II!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import `scipy.stats` for statistical calculations like Z-scores. SciPy is a fundamental library for scientific computing in Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Our Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data: 43,884 rows, 41 columns\n",
      "\n",
      "Numeric columns:\n",
      "  - latitude\n",
      "  - longitude\n",
      "  - last_updated_epoch\n",
      "  - temperature_celsius\n",
      "  - temperature_fahrenheit\n",
      "  - wind_mph\n",
      "  - wind_kph\n",
      "  - wind_degree\n",
      "  - pressure_mb\n",
      "  - pressure_in\n",
      "  ... and 20 more\n"
     ]
    }
   ],
   "source": [
    "# Load the GlobalWeatherRepository dataset\n",
    "weather_path = '../../Datasets/GlobalWeatherRepository.csv'\n",
    "df_weather = pd.read_csv(weather_path)\n",
    "\n",
    "print(f\"Weather Data: {df_weather.shape[0]:,} rows, {df_weather.shape[1]} columns\")\n",
    "print(f\"\\nNumeric columns:\")\n",
    "numeric_cols = df_weather.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols[:10]:\n",
    "    print(f\"  - {col}\")\n",
    "print(f\"  ... and {len(numeric_cols) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food Data: 551 rows, 35 columns\n",
      "\n",
      "Sample columns:\n",
      "['food', 'Caloric Value', 'Fat', 'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats', 'Carbohydrates', 'Sugars', 'Protein', 'Dietary Fiber']\n"
     ]
    }
   ],
   "source": [
    "# Load the Food Nutrition dataset\n",
    "food_path = '../../Datasets/FOOD-DATA-GROUP1.csv'\n",
    "df_food = pd.read_csv(food_path)\n",
    "\n",
    "print(f\"Food Data: {df_food.shape[0]:,} rows, {df_food.shape[1]} columns\")\n",
    "print(f\"\\nSample columns:\")\n",
    "print(df_food.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Understanding Outliers\n",
    "\n",
    "### What is an Outlier?\n",
    "\n",
    "An **outlier** is a data point that differs significantly from other observations. However, not all outliers are errors.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                      TYPES OF OUTLIERS                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  LEGITIMATE OUTLIERS              ERROR OUTLIERS                │\n",
    "│  (Keep or investigate)            (Fix or remove)               │\n",
    "│  ├── Rare but real events         ├── Data entry errors         │\n",
    "│  ├── Exceptional performance      ├── Measurement errors        │\n",
    "│  ├── Black swan events            ├── Processing bugs           │\n",
    "│  └── Natural variation            └── Unit/scale mistakes       │\n",
    "│                                                                 │\n",
    "│  Example: Record-high temp        Example: Temp = 999°C         │\n",
    "│  (Climate: 56.7°C in Death        (Clearly a sensor error       │\n",
    "│   Valley is real)                  or placeholder)              │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### The Outlier Decision Framework\n",
    "\n",
    "Before removing any outlier, ask:\n",
    "\n",
    "1. **Is it possible?** Does this value make physical/logical sense?\n",
    "2. **Is it plausible?** Could this happen in the real world?\n",
    "3. **Is it documented?** Is there an explanation for this value?\n",
    "4. **What's the impact?** How does it affect analysis?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Outlier Detection: IQR Method\n",
    "\n",
    "### The Interquartile Range (IQR) Method\n",
    "\n",
    "The IQR method is robust because it's based on quartiles, not mean/standard deviation (which are sensitive to outliers themselves).\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    IQR OUTLIER DETECTION                        │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│      Q1           Median         Q3                             │\n",
    "│      (25%)         (50%)        (75%)                           │\n",
    "│       │             │            │                              │\n",
    "│  ─────┼─────────────┼────────────┼─────                         │\n",
    "│       │             │            │                              │\n",
    "│       │◄────────────┴────────────►│                             │\n",
    "│       │           IQR            │                              │\n",
    "│                                                                 │\n",
    "│  Lower Fence = Q1 - 1.5 × IQR                                   │\n",
    "│  Upper Fence = Q3 + 1.5 × IQR                                   │\n",
    "│                                                                 │\n",
    "│  Values outside fences = Outliers                               │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "The multiplier 1.5 is conventional. Using 3.0 detects only extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Outlier Analysis (IQR Method)\n",
      "==================================================\n",
      "Q1 (25th percentile): 19.2°C\n",
      "Q3 (75th percentile): 29.1°C\n",
      "IQR: 9.9°C\n",
      "Lower fence: 4.3°C\n",
      "Upper fence: 44.0°C\n",
      "\n",
      "Outliers found: 1,669 (3.80%)\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_iqr(series, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR (Interquartile Range) method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        Numeric series to check for outliers\n",
    "    multiplier : float\n",
    "        IQR multiplier for fence calculation (default: 1.5)\n",
    "        Use 3.0 for extreme outliers only\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains outlier mask, bounds, and statistics\n",
    "    \"\"\"\n",
    "    # Calculate quartiles\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate fences\n",
    "    lower_fence = Q1 - multiplier * IQR\n",
    "    upper_fence = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outlier_mask = (series < lower_fence) | (series > upper_fence)\n",
    "    \n",
    "    return {\n",
    "        'outlier_mask': outlier_mask,\n",
    "        'outlier_count': outlier_mask.sum(),\n",
    "        'outlier_pct': outlier_mask.sum() / len(series) * 100,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'lower_fence': lower_fence,\n",
    "        'upper_fence': upper_fence,\n",
    "        'multiplier': multiplier\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply to temperature data\n",
    "temp_outliers = detect_outliers_iqr(df_weather['temperature_celsius'])\n",
    "\n",
    "print(\"Temperature Outlier Analysis (IQR Method)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Q1 (25th percentile): {temp_outliers['Q1']:.1f}°C\")\n",
    "print(f\"Q3 (75th percentile): {temp_outliers['Q3']:.1f}°C\")\n",
    "print(f\"IQR: {temp_outliers['IQR']:.1f}°C\")\n",
    "print(f\"Lower fence: {temp_outliers['lower_fence']:.1f}°C\")\n",
    "print(f\"Upper fence: {temp_outliers['upper_fence']:.1f}°C\")\n",
    "print(f\"\\nOutliers found: {temp_outliers['outlier_count']:,} ({temp_outliers['outlier_pct']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IQR method identified temperature values outside the fences. Let's examine these outliers to determine if they're errors or legitimate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Temperature Outliers:\n",
      "  Minimum: -24.2°C\n",
      "  Maximum: 49.2°C\n",
      "  Mean: 4.8°C\n",
      "\n",
      "Sample outlier records:\n",
      "  country location_name  temperature_celsius condition_text\n",
      "    Chile      Santiago                  1.0          Clear\n",
      "    Chile      Santiago                  2.0          Sunny\n",
      "Australia      Canberra                 -1.0          Clear\n",
      "    Chile      Santiago                  3.0           Mist\n",
      "  Iceland     Grindavik                  4.0     Light rain\n",
      "    Sudan      Khartoum                 44.1          Sunny\n",
      "Australia      Canberra                  3.0          Clear\n",
      "     Chad     N'djamena                 44.0          Sunny\n",
      "     Chad     N'djamena                 45.0          Sunny\n",
      "Australia      Canberra                  1.0          Clear\n"
     ]
    }
   ],
   "source": [
    "# Examine the outliers\n",
    "outlier_temps = df_weather[temp_outliers['outlier_mask']]['temperature_celsius']\n",
    "\n",
    "print(\"Distribution of Temperature Outliers:\")\n",
    "print(f\"  Minimum: {outlier_temps.min():.1f}°C\")\n",
    "print(f\"  Maximum: {outlier_temps.max():.1f}°C\")\n",
    "print(f\"  Mean: {outlier_temps.mean():.1f}°C\")\n",
    "\n",
    "print(\"\\nSample outlier records:\")\n",
    "outlier_records = df_weather[temp_outliers['outlier_mask']][['country', 'location_name', 'temperature_celsius', 'condition_text']].head(10)\n",
    "print(outlier_records.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the outliers, we can assess whether they are reasonable for their locations. Temperatures below -10°C are normal for northern countries in winter, and above 35°C is common in desert regions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Z-Score Based Detection\n",
    "\n",
    "### What is a Z-Score?\n",
    "\n",
    "A Z-score measures how many standard deviations a value is from the mean:\n",
    "\n",
    "$$Z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- $x$ = the value\n",
    "- $\\mu$ = mean of the data\n",
    "- $\\sigma$ = standard deviation\n",
    "\n",
    "**Common thresholds:**\n",
    "- |Z| > 2: Unusual (5% of normally distributed data)\n",
    "- |Z| > 3: Very unusual (0.3% of data)\n",
    "- |Z| > 4: Extremely unusual (0.006% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Outlier Analysis (Z-Score Method)\n",
      "==================================================\n",
      "Mean: 23.7°C\n",
      "Standard Deviation: 8.7°C\n",
      "Threshold: |Z| > 3.0\n",
      "\n",
      "Outliers found: 230 (0.52%)\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_zscore(series, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Detect outliers using Z-score method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        Numeric series to check\n",
    "    threshold : float\n",
    "        Z-score threshold (default: 3.0)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains outlier information and z-scores\n",
    "    \"\"\"\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    \n",
    "    # Calculate Z-scores\n",
    "    z_scores = (series - mean) / std\n",
    "    \n",
    "    # Identify outliers\n",
    "    outlier_mask = np.abs(z_scores) > threshold\n",
    "    \n",
    "    return {\n",
    "        'outlier_mask': outlier_mask,\n",
    "        'outlier_count': outlier_mask.sum(),\n",
    "        'outlier_pct': outlier_mask.sum() / len(series) * 100,\n",
    "        'z_scores': z_scores,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply Z-score detection to temperature\n",
    "zscore_outliers = detect_outliers_zscore(df_weather['temperature_celsius'], threshold=3.0)\n",
    "\n",
    "print(\"Temperature Outlier Analysis (Z-Score Method)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean: {zscore_outliers['mean']:.1f}°C\")\n",
    "print(f\"Standard Deviation: {zscore_outliers['std']:.1f}°C\")\n",
    "print(f\"Threshold: |Z| > {zscore_outliers['threshold']}\")\n",
    "print(f\"\\nOutliers found: {zscore_outliers['outlier_count']:,} ({zscore_outliers['outlier_pct']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Z-score method typically finds fewer outliers than IQR because it uses a threshold of 3 standard deviations, which corresponds to very extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Outlier Detection Methods\n",
      "==================================================\n",
      "             Column  IQR Outliers IQR %  Z-Score Outliers Z-Score %\n",
      "temperature_celsius          1669 3.80%               230     0.52%\n",
      "           humidity             0 0.00%                 0     0.00%\n",
      "           wind_kph           554 1.26%                18     0.04%\n",
      "        pressure_mb          2718 6.19%               369     0.84%\n"
     ]
    }
   ],
   "source": [
    "# Compare IQR and Z-score methods\n",
    "\n",
    "print(\"Comparison of Outlier Detection Methods\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test on multiple columns\n",
    "test_columns = ['temperature_celsius', 'humidity', 'wind_kph', 'pressure_mb']\n",
    "\n",
    "comparison_data = []\n",
    "for col in test_columns:\n",
    "    if col in df_weather.columns:\n",
    "        iqr_result = detect_outliers_iqr(df_weather[col].dropna())\n",
    "        zscore_result = detect_outliers_zscore(df_weather[col].dropna())\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Column': col,\n",
    "            'IQR Outliers': iqr_result['outlier_count'],\n",
    "            'IQR %': f\"{iqr_result['outlier_pct']:.2f}%\",\n",
    "            'Z-Score Outliers': zscore_result['outlier_count'],\n",
    "            'Z-Score %': f\"{zscore_result['outlier_pct']:.2f}%\"\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows that different methods can yield different results. IQR is generally more conservative (finds more outliers) because it doesn't assume normality.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Domain-Based Outlier Rules\n",
    "\n",
    "### The Importance of Domain Knowledge\n",
    "\n",
    "Statistical methods are blind to context. Domain knowledge tells us what's actually possible:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│               DOMAIN-BASED VALIDATION RULES                     │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  PHYSICAL CONSTRAINTS           BUSINESS RULES                  │\n",
    "│  ├── Temperature: -90 to 60°C   ├── Price: must be positive    │\n",
    "│  ├── Humidity: 0 to 100%        ├── Age: 0 to 150 years        │\n",
    "│  ├── Latitude: -90 to 90        ├── Quantity: must be integer  │\n",
    "│  └── Pressure: 870 to 1085 mb   └── Date: not in future        │\n",
    "│                                                                 │\n",
    "│  RELATIONAL CONSTRAINTS         TEMPORAL CONSTRAINTS            │\n",
    "│  ├── Start date < End date      ├── Year: 1900 to current      │\n",
    "│  ├── Min value < Max value      ├── Month: 1 to 12             │\n",
    "│  └── Part of whole ≤ whole      └── Hour: 0 to 23              │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Validation Results\n",
      "======================================================================\n",
      "\n",
      "latitude:\n",
      "  Rule: Geographic latitude\n",
      "  Valid range: [-90, 90]\n",
      "  Actual range: [-41.3, 64.2]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "longitude:\n",
      "  Rule: Geographic longitude\n",
      "  Valid range: [-180, 180]\n",
      "  Actual range: [-175.2, 179.2]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "temperature_celsius:\n",
      "  Rule: Earth temperature range\n",
      "  Valid range: [-90, 60]\n",
      "  Actual range: [-24.2, 49.2]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "temperature_fahrenheit:\n",
      "  Rule: Earth temperature range\n",
      "  Valid range: [-130, 140]\n",
      "  Actual range: [-11.6, 120.6]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "wind_kph:\n",
      "  Rule: Wind speed (max tornado)\n",
      "  Valid range: [0, 410]\n",
      "  Actual range: [3.6, 2963.2]\n",
      "  Violations: 1 (0.00%)\n",
      "\n",
      "pressure_mb:\n",
      "  Rule: Atmospheric pressure\n",
      "  Valid range: [870, 1085]\n",
      "  Actual range: [971.0, 1080.0]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "humidity:\n",
      "  Rule: Percentage\n",
      "  Valid range: [0, 100]\n",
      "  Actual range: [2.0, 100.0]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "cloud:\n",
      "  Rule: Cloud cover percentage\n",
      "  Valid range: [0, 100]\n",
      "  Actual range: [0.0, 100.0]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "visibility_km:\n",
      "  Rule: Visibility range\n",
      "  Valid range: [0, 100]\n",
      "  Actual range: [0.0, 32.0]\n",
      "  Violations: 0 (0.00%)\n",
      "\n",
      "uv_index:\n",
      "  Rule: UV Index scale\n",
      "  Valid range: [0, 15]\n",
      "  Actual range: [0.0, 15.4]\n",
      "  Violations: 9 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "class DomainValidator:\n",
    "    \"\"\"\n",
    "    Domain-based validation rules for weather data.\n",
    "    \n",
    "    This class encapsulates physical constraints that values must satisfy\n",
    "    regardless of statistical distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define valid ranges based on physical constraints\n",
    "    WEATHER_RULES = {\n",
    "        'temperature_celsius': {'min': -90, 'max': 60, 'description': 'Earth temperature range'},\n",
    "        'temperature_fahrenheit': {'min': -130, 'max': 140, 'description': 'Earth temperature range'},\n",
    "        'humidity': {'min': 0, 'max': 100, 'description': 'Percentage'},\n",
    "        'pressure_mb': {'min': 870, 'max': 1085, 'description': 'Atmospheric pressure'},\n",
    "        'wind_kph': {'min': 0, 'max': 410, 'description': 'Wind speed (max tornado)'},\n",
    "        'visibility_km': {'min': 0, 'max': 100, 'description': 'Visibility range'},\n",
    "        'uv_index': {'min': 0, 'max': 15, 'description': 'UV Index scale'},\n",
    "        'cloud': {'min': 0, 'max': 100, 'description': 'Cloud cover percentage'},\n",
    "        'latitude': {'min': -90, 'max': 90, 'description': 'Geographic latitude'},\n",
    "        'longitude': {'min': -180, 'max': 180, 'description': 'Geographic longitude'},\n",
    "    }\n",
    "    \n",
    "    def __init__(self, custom_rules=None):\n",
    "        \"\"\"\n",
    "        Initialize with optional custom rules.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        custom_rules : dict\n",
    "            Additional rules to merge with defaults\n",
    "        \"\"\"\n",
    "        self.rules = self.WEATHER_RULES.copy()\n",
    "        if custom_rules:\n",
    "            self.rules.update(custom_rules)\n",
    "    \n",
    "    def validate_column(self, series, column_name):\n",
    "        \"\"\"\n",
    "        Validate a column against domain rules.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Validation results\n",
    "        \"\"\"\n",
    "        if column_name not in self.rules:\n",
    "            return {'status': 'no_rule', 'message': f'No rule defined for {column_name}'}\n",
    "        \n",
    "        rule = self.rules[column_name]\n",
    "        min_val = rule['min']\n",
    "        max_val = rule['max']\n",
    "        \n",
    "        # Find violations\n",
    "        below_min = series < min_val\n",
    "        above_max = series > max_val\n",
    "        violations = below_min | above_max\n",
    "        \n",
    "        return {\n",
    "            'status': 'validated',\n",
    "            'column': column_name,\n",
    "            'rule': rule['description'],\n",
    "            'valid_range': f\"[{min_val}, {max_val}]\",\n",
    "            'violations_mask': violations,\n",
    "            'violation_count': violations.sum(),\n",
    "            'violation_pct': violations.sum() / len(series) * 100,\n",
    "            'below_min_count': below_min.sum(),\n",
    "            'above_max_count': above_max.sum(),\n",
    "            'actual_min': series.min(),\n",
    "            'actual_max': series.max()\n",
    "        }\n",
    "    \n",
    "    def validate_dataframe(self, df):\n",
    "        \"\"\"\n",
    "        Validate all applicable columns in a DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        list : Validation results for each column\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for col in df.columns:\n",
    "            if col in self.rules:\n",
    "                result = self.validate_column(df[col], col)\n",
    "                results.append(result)\n",
    "        return results\n",
    "\n",
    "\n",
    "# Create validator and run checks\n",
    "validator = DomainValidator()\n",
    "validation_results = validator.validate_dataframe(df_weather)\n",
    "\n",
    "print(\"Domain Validation Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for result in validation_results:\n",
    "    if result['status'] == 'validated':\n",
    "        print(f\"\\n{result['column']}:\")\n",
    "        print(f\"  Rule: {result['rule']}\")\n",
    "        print(f\"  Valid range: {result['valid_range']}\")\n",
    "        print(f\"  Actual range: [{result['actual_min']:.1f}, {result['actual_max']:.1f}]\")\n",
    "        print(f\"  Violations: {result['violation_count']:,} ({result['violation_pct']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain validator checks each column against physical constraints. This catches errors that statistical methods might miss - for example, a temperature of 200°C would have a high Z-score, but domain validation immediately flags it as physically impossible.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Value Patterns and Handling\n",
    "\n",
    "### Types of Missingness\n",
    "\n",
    "Understanding WHY data is missing is crucial for choosing the right handling strategy:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│               MISSING DATA MECHANISMS                           │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  MCAR - Missing Completely At Random                            │\n",
    "│  ├── Missingness is random, unrelated to any data               │\n",
    "│  ├── Example: Sensor randomly fails                             │\n",
    "│  └── Safe to drop or impute with mean/median                    │\n",
    "│                                                                 │\n",
    "│  MAR - Missing At Random                                        │\n",
    "│  ├── Missingness depends on observed data                       │\n",
    "│  ├── Example: Older equipment more likely to fail               │\n",
    "│  └── Use regression or group-based imputation                   │\n",
    "│                                                                 │\n",
    "│  MNAR - Missing Not At Random                                   │\n",
    "│  ├── Missingness depends on the missing value itself            │\n",
    "│  ├── Example: High-income people refuse to report income        │\n",
    "│  └── Most problematic - may need domain expertise               │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Analysis - Weather Data\n",
      "============================================================\n",
      "\n",
      "No missing values found!\n",
      "\n",
      "Summary by Category:\n",
      "category\n",
      "Complete    41\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(df):\n",
    "    \"\"\"\n",
    "    Comprehensive missing value analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame to analyze\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Missing value statistics per column\n",
    "    \"\"\"\n",
    "    # Calculate missing stats\n",
    "    missing_count = df.isnull().sum()\n",
    "    missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    missing_df = pd.DataFrame({\n",
    "        'column': df.columns,\n",
    "        'missing_count': missing_count.values,\n",
    "        'missing_pct': missing_pct.values,\n",
    "        'dtype': df.dtypes.values\n",
    "    })\n",
    "    \n",
    "    # Sort by missing percentage\n",
    "    missing_df = missing_df.sort_values('missing_pct', ascending=False)\n",
    "    \n",
    "    # Add category\n",
    "    def categorize_missing(pct):\n",
    "        if pct == 0:\n",
    "            return 'Complete'\n",
    "        elif pct < 5:\n",
    "            return 'Low (<5%)'\n",
    "        elif pct < 20:\n",
    "            return 'Moderate (5-20%)'\n",
    "        elif pct < 50:\n",
    "            return 'High (20-50%)'\n",
    "        else:\n",
    "            return 'Very High (>50%)'\n",
    "    \n",
    "    missing_df['category'] = missing_df['missing_pct'].apply(categorize_missing)\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "\n",
    "# Analyze missing values in weather data\n",
    "missing_analysis = analyze_missing_values(df_weather)\n",
    "\n",
    "print(\"Missing Value Analysis - Weather Data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show columns with missing values\n",
    "has_missing = missing_analysis[missing_analysis['missing_count'] > 0]\n",
    "\n",
    "if len(has_missing) > 0:\n",
    "    print(f\"\\nColumns with missing values: {len(has_missing)}\")\n",
    "    print(has_missing[['column', 'missing_count', 'missing_pct', 'category']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo missing values found!\")\n",
    "\n",
    "# Summary by category\n",
    "print(\"\\nSummary by Category:\")\n",
    "print(missing_analysis['category'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis categorizes columns by their missing value rates. This helps prioritize which columns need attention and what strategies to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data with missing values:\n",
      "     A     B    C\n",
      "0  1.0  10.0    x\n",
      "1  2.0   NaN    y\n",
      "2  NaN  30.0  NaN\n",
      "3  4.0   NaN    x\n",
      "4  5.0  50.0    y\n",
      "\n",
      "Strategy: fill_median (numeric only)\n",
      "     A     B    C\n",
      "0  1.0  10.0    x\n",
      "1  2.0  30.0    y\n",
      "2  3.0  30.0  NaN\n",
      "3  4.0  30.0    x\n",
      "4  5.0  50.0    y\n",
      "\n",
      "Strategy: auto (median for numeric, mode for categorical)\n",
      "     A     B  C\n",
      "0  1.0  10.0  x\n",
      "1  2.0  30.0  y\n",
      "2  3.0  30.0  x\n",
      "3  4.0  30.0  x\n",
      "4  5.0  50.0  y\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, strategy='auto', fill_value=None):\n",
    "    \"\"\"\n",
    "    Handle missing values with various strategies.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with missing values\n",
    "    strategy : str\n",
    "        'drop_rows' - Remove rows with any missing\n",
    "        'drop_cols' - Remove columns with any missing\n",
    "        'fill_mean' - Fill numeric with mean\n",
    "        'fill_median' - Fill numeric with median\n",
    "        'fill_mode' - Fill all with mode\n",
    "        'fill_value' - Fill with specified value\n",
    "        'auto' - Use appropriate strategy per column type\n",
    "    fill_value : any\n",
    "        Value to use with 'fill_value' strategy\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with missing values handled\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    if strategy == 'drop_rows':\n",
    "        result = result.dropna()\n",
    "        \n",
    "    elif strategy == 'drop_cols':\n",
    "        result = result.dropna(axis=1)\n",
    "        \n",
    "    elif strategy == 'fill_mean':\n",
    "        numeric_cols = result.select_dtypes(include=[np.number]).columns\n",
    "        result[numeric_cols] = result[numeric_cols].fillna(result[numeric_cols].mean())\n",
    "        \n",
    "    elif strategy == 'fill_median':\n",
    "        numeric_cols = result.select_dtypes(include=[np.number]).columns\n",
    "        result[numeric_cols] = result[numeric_cols].fillna(result[numeric_cols].median())\n",
    "        \n",
    "    elif strategy == 'fill_mode':\n",
    "        for col in result.columns:\n",
    "            result[col] = result[col].fillna(result[col].mode().iloc[0] if len(result[col].mode()) > 0 else np.nan)\n",
    "            \n",
    "    elif strategy == 'fill_value':\n",
    "        result = result.fillna(fill_value)\n",
    "        \n",
    "    elif strategy == 'auto':\n",
    "        # Numeric: fill with median (robust to outliers)\n",
    "        numeric_cols = result.select_dtypes(include=[np.number]).columns\n",
    "        result[numeric_cols] = result[numeric_cols].fillna(result[numeric_cols].median())\n",
    "        \n",
    "        # Categorical/string: fill with mode\n",
    "        non_numeric_cols = result.select_dtypes(exclude=[np.number]).columns\n",
    "        for col in non_numeric_cols:\n",
    "            mode_val = result[col].mode()\n",
    "            if len(mode_val) > 0:\n",
    "                result[col] = result[col].fillna(mode_val.iloc[0])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Demonstrate different strategies on a sample with missing values\n",
    "sample_df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [10, np.nan, 30, np.nan, 50],\n",
    "    'C': ['x', 'y', np.nan, 'x', 'y']\n",
    "})\n",
    "\n",
    "print(\"Original data with missing values:\")\n",
    "print(sample_df)\n",
    "\n",
    "print(\"\\nStrategy: fill_median (numeric only)\")\n",
    "print(handle_missing_values(sample_df, strategy='fill_median'))\n",
    "\n",
    "print(\"\\nStrategy: auto (median for numeric, mode for categorical)\")\n",
    "print(handle_missing_values(sample_df, strategy='auto'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `handle_missing_values` function provides multiple strategies. The 'auto' strategy is recommended for mixed-type DataFrames because it:\n",
    "- Uses **median** for numeric columns (robust to outliers)\n",
    "- Uses **mode** for categorical columns (most frequent value)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation Rules and Constraints\n",
    "\n",
    "### Building a Validation Framework\n",
    "\n",
    "Production data pipelines need systematic validation. We'll build a framework that checks:\n",
    "\n",
    "1. **Schema validation**: Are all required columns present?\n",
    "2. **Type validation**: Are data types correct?\n",
    "3. **Range validation**: Are values within acceptable bounds?\n",
    "4. **Format validation**: Do strings match expected patterns?\n",
    "5. **Uniqueness validation**: Are key columns unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report\n",
      "==================================================\n",
      "Status: PASS\n",
      "\n",
      "Summary:\n",
      "  Total checks: 7\n",
      "  Passed: 7\n",
      "  Failed: 0\n",
      "  Pass rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "class DataValidator:\n",
    "    \"\"\"\n",
    "    Comprehensive data validation framework.\n",
    "    \n",
    "    This class runs multiple validation checks and generates\n",
    "    a detailed report of any issues found.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize validator with DataFrame to check.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.issues = []\n",
    "        self.checks_passed = 0\n",
    "        self.checks_failed = 0\n",
    "    \n",
    "    def _log_issue(self, check_name, severity, message, details=None):\n",
    "        \"\"\"Record a validation issue.\"\"\"\n",
    "        self.issues.append({\n",
    "            'check': check_name,\n",
    "            'severity': severity,  # 'error', 'warning', 'info'\n",
    "            'message': message,\n",
    "            'details': details\n",
    "        })\n",
    "        if severity == 'error':\n",
    "            self.checks_failed += 1\n",
    "    \n",
    "    def _log_pass(self, check_name):\n",
    "        \"\"\"Record a passed check.\"\"\"\n",
    "        self.checks_passed += 1\n",
    "    \n",
    "    def check_required_columns(self, required_cols):\n",
    "        \"\"\"\n",
    "        Verify all required columns exist.\n",
    "        \"\"\"\n",
    "        missing = [c for c in required_cols if c not in self.df.columns]\n",
    "        \n",
    "        if missing:\n",
    "            self._log_issue(\n",
    "                'required_columns',\n",
    "                'error',\n",
    "                f\"Missing {len(missing)} required columns\",\n",
    "                missing\n",
    "            )\n",
    "        else:\n",
    "            self._log_pass('required_columns')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def check_no_nulls(self, columns):\n",
    "        \"\"\"\n",
    "        Verify specified columns have no null values.\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            if col in self.df.columns:\n",
    "                null_count = self.df[col].isnull().sum()\n",
    "                if null_count > 0:\n",
    "                    self._log_issue(\n",
    "                        'no_nulls',\n",
    "                        'error',\n",
    "                        f\"Column '{col}' has {null_count:,} null values\",\n",
    "                        {'column': col, 'null_count': null_count}\n",
    "                    )\n",
    "                else:\n",
    "                    self._log_pass('no_nulls')\n",
    "        return self\n",
    "    \n",
    "    def check_unique(self, columns):\n",
    "        \"\"\"\n",
    "        Verify specified columns have unique values.\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            if col in self.df.columns:\n",
    "                dup_count = self.df[col].duplicated().sum()\n",
    "                if dup_count > 0:\n",
    "                    self._log_issue(\n",
    "                        'unique_values',\n",
    "                        'error',\n",
    "                        f\"Column '{col}' has {dup_count:,} duplicate values\",\n",
    "                        {'column': col, 'duplicate_count': dup_count}\n",
    "                    )\n",
    "                else:\n",
    "                    self._log_pass('unique_values')\n",
    "        return self\n",
    "    \n",
    "    def check_range(self, column, min_val=None, max_val=None):\n",
    "        \"\"\"\n",
    "        Verify column values are within specified range.\n",
    "        \"\"\"\n",
    "        if column not in self.df.columns:\n",
    "            return self\n",
    "        \n",
    "        violations = 0\n",
    "        if min_val is not None:\n",
    "            violations += (self.df[column] < min_val).sum()\n",
    "        if max_val is not None:\n",
    "            violations += (self.df[column] > max_val).sum()\n",
    "        \n",
    "        if violations > 0:\n",
    "            self._log_issue(\n",
    "                'range_check',\n",
    "                'warning',\n",
    "                f\"Column '{column}' has {violations:,} values outside [{min_val}, {max_val}]\",\n",
    "                {'column': column, 'violations': violations}\n",
    "            )\n",
    "        else:\n",
    "            self._log_pass('range_check')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def check_data_type(self, column, expected_type):\n",
    "        \"\"\"\n",
    "        Verify column has expected data type.\n",
    "        \"\"\"\n",
    "        if column not in self.df.columns:\n",
    "            return self\n",
    "        \n",
    "        actual_type = str(self.df[column].dtype)\n",
    "        \n",
    "        if expected_type not in actual_type:\n",
    "            self._log_issue(\n",
    "                'data_type',\n",
    "                'warning',\n",
    "                f\"Column '{column}' type is {actual_type}, expected {expected_type}\",\n",
    "                {'column': column, 'actual': actual_type, 'expected': expected_type}\n",
    "            )\n",
    "        else:\n",
    "            self._log_pass('data_type')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def check_row_count(self, min_rows=1, max_rows=None):\n",
    "        \"\"\"\n",
    "        Verify row count is within expected range.\n",
    "        \"\"\"\n",
    "        row_count = len(self.df)\n",
    "        \n",
    "        if row_count < min_rows:\n",
    "            self._log_issue(\n",
    "                'row_count',\n",
    "                'error',\n",
    "                f\"Too few rows: {row_count:,} (minimum: {min_rows:,})\"\n",
    "            )\n",
    "        elif max_rows and row_count > max_rows:\n",
    "            self._log_issue(\n",
    "                'row_count',\n",
    "                'warning',\n",
    "                f\"Too many rows: {row_count:,} (maximum: {max_rows:,})\"\n",
    "            )\n",
    "        else:\n",
    "            self._log_pass('row_count')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_report(self):\n",
    "        \"\"\"\n",
    "        Generate validation report.\n",
    "        \"\"\"\n",
    "        total_checks = self.checks_passed + self.checks_failed\n",
    "        \n",
    "        report = {\n",
    "            'summary': {\n",
    "                'total_checks': total_checks,\n",
    "                'passed': self.checks_passed,\n",
    "                'failed': self.checks_failed,\n",
    "                'pass_rate': self.checks_passed / total_checks * 100 if total_checks > 0 else 0\n",
    "            },\n",
    "            'issues': self.issues,\n",
    "            'status': 'PASS' if self.checks_failed == 0 else 'FAIL'\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "# Run validation on weather data\n",
    "validator = DataValidator(df_weather)\n",
    "\n",
    "report = (\n",
    "    validator\n",
    "    .check_required_columns(['country', 'location_name', 'temperature_celsius'])\n",
    "    .check_no_nulls(['country', 'location_name'])\n",
    "    .check_range('temperature_celsius', min_val=-90, max_val=60)\n",
    "    .check_range('humidity', min_val=0, max_val=100)\n",
    "    .check_data_type('temperature_celsius', 'float')\n",
    "    .check_row_count(min_rows=1000)\n",
    "    .get_report()\n",
    ")\n",
    "\n",
    "print(\"Validation Report\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Status: {report['status']}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total checks: {report['summary']['total_checks']}\")\n",
    "print(f\"  Passed: {report['summary']['passed']}\")\n",
    "print(f\"  Failed: {report['summary']['failed']}\")\n",
    "print(f\"  Pass rate: {report['summary']['pass_rate']:.1f}%\")\n",
    "\n",
    "if report['issues']:\n",
    "    print(f\"\\nIssues Found ({len(report['issues'])}):\") \n",
    "    for issue in report['issues']:\n",
    "        print(f\"  [{issue['severity'].upper()}] {issue['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataValidator` class provides a fluent interface for chaining validation checks. The report summarizes all findings with severity levels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Referential Integrity Checks\n",
    "\n",
    "### What is Referential Integrity?\n",
    "\n",
    "Referential integrity ensures that relationships between tables remain consistent:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│               REFERENTIAL INTEGRITY                             │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│   COUNTRIES TABLE              WEATHER TABLE                    │\n",
    "│   ┌───────────────┐            ┌───────────────┐               │\n",
    "│   │ country_code  │◄───────────│ country       │               │\n",
    "│   │ country_name  │            │ temperature   │               │\n",
    "│   │ region        │            │ humidity      │               │\n",
    "│   └───────────────┘            └───────────────┘               │\n",
    "│                                                                 │\n",
    "│   Every country in WEATHER must exist in COUNTRIES             │\n",
    "│   (Foreign key constraint)                                     │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referential Integrity Check\n",
      "==================================================\n",
      "Child column: country\n",
      "Parent column: country_name\n",
      "\n",
      "Child unique values: 210\n",
      "Parent unique values: 210\n",
      "\n",
      "Orphan values: 0\n",
      "Orphan rows: 0\n",
      "\n",
      "Integrity valid: True\n"
     ]
    }
   ],
   "source": [
    "def check_referential_integrity(child_df, child_col, parent_df, parent_col):\n",
    "    \"\"\"\n",
    "    Check that all values in child column exist in parent column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    child_df : pd.DataFrame\n",
    "        DataFrame with foreign key column\n",
    "    child_col : str\n",
    "        Column name of the foreign key\n",
    "    parent_df : pd.DataFrame\n",
    "        DataFrame with primary key column\n",
    "    parent_col : str\n",
    "        Column name of the primary key\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Integrity check results\n",
    "    \"\"\"\n",
    "    # Get unique values from each\n",
    "    child_values = set(child_df[child_col].dropna().unique())\n",
    "    parent_values = set(parent_df[parent_col].dropna().unique())\n",
    "    \n",
    "    # Find orphans (in child but not in parent)\n",
    "    orphans = child_values - parent_values\n",
    "    \n",
    "    # Find unused (in parent but not in child)\n",
    "    unused = parent_values - child_values\n",
    "    \n",
    "    # Count orphan rows\n",
    "    orphan_rows = child_df[child_df[child_col].isin(orphans)]\n",
    "    \n",
    "    return {\n",
    "        'child_column': child_col,\n",
    "        'parent_column': parent_col,\n",
    "        'child_unique_values': len(child_values),\n",
    "        'parent_unique_values': len(parent_values),\n",
    "        'orphan_values': len(orphans),\n",
    "        'orphan_rows': len(orphan_rows),\n",
    "        'orphan_list': list(orphans)[:10],  # First 10\n",
    "        'unused_parent_values': len(unused),\n",
    "        'integrity_valid': len(orphans) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "# Create a reference table for valid countries\n",
    "# In practice, this would come from a master data source\n",
    "valid_countries = pd.DataFrame({\n",
    "    'country_name': df_weather['country'].unique()\n",
    "})\n",
    "\n",
    "# Simulate an integrity check\n",
    "# (In this case, all countries match because we derived the reference from the data)\n",
    "integrity_result = check_referential_integrity(\n",
    "    df_weather, 'country',\n",
    "    valid_countries, 'country_name'\n",
    ")\n",
    "\n",
    "print(\"Referential Integrity Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Child column: {integrity_result['child_column']}\")\n",
    "print(f\"Parent column: {integrity_result['parent_column']}\")\n",
    "print(f\"\\nChild unique values: {integrity_result['child_unique_values']}\")\n",
    "print(f\"Parent unique values: {integrity_result['parent_unique_values']}\")\n",
    "print(f\"\\nOrphan values: {integrity_result['orphan_values']}\")\n",
    "print(f\"Orphan rows: {integrity_result['orphan_rows']}\")\n",
    "print(f\"\\nIntegrity valid: {integrity_result['integrity_valid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referential integrity checks ensure consistency across related datasets. Orphan records (values in child that don't exist in parent) often indicate data quality issues or incomplete data loads.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Scoring Framework\n",
    "\n",
    "### Why Score Data Quality?\n",
    "\n",
    "A single quality score helps:\n",
    "- **Track trends**: Is quality improving or declining?\n",
    "- **Set thresholds**: Define minimum acceptable quality\n",
    "- **Compare datasets**: Which source is more reliable?\n",
    "- **Prioritize fixes**: Focus on biggest quality gaps\n",
    "\n",
    "### Quality Dimensions\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                  DATA QUALITY DIMENSIONS                        │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  COMPLETENESS (25%)           VALIDITY (25%)                    │\n",
    "│  ├── Missing value rate       ├── Values within valid range    │\n",
    "│  └── Required fields present  └── Correct data types           │\n",
    "│                                                                 │\n",
    "│  UNIQUENESS (25%)             CONSISTENCY (25%)                 │\n",
    "│  ├── No duplicate records     ├── Referential integrity        │\n",
    "│  └── Key uniqueness           └── Cross-column logic           │\n",
    "│                                                                 │\n",
    "│           OVERALL SCORE = Weighted Average                      │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityScorer:\n",
    "    \"\"\"\n",
    "    Calculate data quality scores across multiple dimensions.\n",
    "    \n",
    "    Dimensions:\n",
    "    - Completeness: % of non-null values\n",
    "    - Validity: % of values within valid ranges\n",
    "    - Uniqueness: % of unique rows (vs duplicates)\n",
    "    - Consistency: % passing consistency rules\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.scores = {}\n",
    "        self.details = {}\n",
    "    \n",
    "    def score_completeness(self, required_columns=None):\n",
    "        \"\"\"\n",
    "        Score based on missing value rate.\n",
    "        \"\"\"\n",
    "        if required_columns:\n",
    "            cols_to_check = [c for c in required_columns if c in self.df.columns]\n",
    "        else:\n",
    "            cols_to_check = self.df.columns.tolist()\n",
    "        \n",
    "        if not cols_to_check:\n",
    "            self.scores['completeness'] = 100.0\n",
    "            return self\n",
    "        \n",
    "        total_cells = len(self.df) * len(cols_to_check)\n",
    "        missing_cells = self.df[cols_to_check].isnull().sum().sum()\n",
    "        \n",
    "        score = (1 - missing_cells / total_cells) * 100\n",
    "        \n",
    "        self.scores['completeness'] = round(score, 2)\n",
    "        self.details['completeness'] = {\n",
    "            'total_cells': total_cells,\n",
    "            'missing_cells': missing_cells,\n",
    "            'columns_checked': len(cols_to_check)\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def score_validity(self, rules):\n",
    "        \"\"\"\n",
    "        Score based on values passing validation rules.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rules : dict\n",
    "            {column: {'min': x, 'max': y}} format\n",
    "        \"\"\"\n",
    "        total_values = 0\n",
    "        valid_values = 0\n",
    "        \n",
    "        for col, rule in rules.items():\n",
    "            if col not in self.df.columns:\n",
    "                continue\n",
    "            \n",
    "            col_data = self.df[col].dropna()\n",
    "            total_values += len(col_data)\n",
    "            \n",
    "            valid_mask = pd.Series([True] * len(col_data), index=col_data.index)\n",
    "            \n",
    "            if 'min' in rule:\n",
    "                valid_mask &= (col_data >= rule['min'])\n",
    "            if 'max' in rule:\n",
    "                valid_mask &= (col_data <= rule['max'])\n",
    "            \n",
    "            valid_values += valid_mask.sum()\n",
    "        \n",
    "        score = (valid_values / total_values * 100) if total_values > 0 else 100\n",
    "        \n",
    "        self.scores['validity'] = round(score, 2)\n",
    "        self.details['validity'] = {\n",
    "            'total_values': total_values,\n",
    "            'valid_values': valid_values,\n",
    "            'rules_applied': len(rules)\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def score_uniqueness(self, key_columns=None):\n",
    "        \"\"\"\n",
    "        Score based on duplicate rate.\n",
    "        \"\"\"\n",
    "        if key_columns:\n",
    "            dup_count = self.df.duplicated(subset=key_columns).sum()\n",
    "        else:\n",
    "            dup_count = self.df.duplicated().sum()\n",
    "        \n",
    "        score = (1 - dup_count / len(self.df)) * 100\n",
    "        \n",
    "        self.scores['uniqueness'] = round(score, 2)\n",
    "        self.details['uniqueness'] = {\n",
    "            'total_rows': len(self.df),\n",
    "            'duplicate_rows': dup_count,\n",
    "            'key_columns': key_columns\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def score_consistency(self, rules):\n",
    "        \"\"\"\n",
    "        Score based on cross-column consistency rules.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rules : list of dict\n",
    "            [{'check': lambda df: condition, 'name': 'rule_name'}, ...]\n",
    "        \"\"\"\n",
    "        if not rules:\n",
    "            self.scores['consistency'] = 100.0\n",
    "            return self\n",
    "        \n",
    "        total_checks = len(rules) * len(self.df)\n",
    "        passed_checks = 0\n",
    "        \n",
    "        rule_results = []\n",
    "        for rule in rules:\n",
    "            try:\n",
    "                passed = rule['check'](self.df).sum()\n",
    "                passed_checks += passed\n",
    "                rule_results.append({\n",
    "                    'name': rule['name'],\n",
    "                    'passed': passed,\n",
    "                    'total': len(self.df),\n",
    "                    'pass_rate': passed / len(self.df) * 100\n",
    "                })\n",
    "            except Exception as e:\n",
    "                rule_results.append({'name': rule['name'], 'error': str(e)})\n",
    "        \n",
    "        score = (passed_checks / total_checks * 100) if total_checks > 0 else 100\n",
    "        \n",
    "        self.scores['consistency'] = round(score, 2)\n",
    "        self.details['consistency'] = {'rule_results': rule_results}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def calculate_overall(self, weights=None):\n",
    "        \"\"\"\n",
    "        Calculate weighted overall score.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'completeness': 0.25,\n",
    "                'validity': 0.25,\n",
    "                'uniqueness': 0.25,\n",
    "                'consistency': 0.25\n",
    "            }\n",
    "        \n",
    "        overall = 0\n",
    "        total_weight = 0\n",
    "        \n",
    "        for dimension, weight in weights.items():\n",
    "            if dimension in self.scores:\n",
    "                overall += self.scores[dimension] * weight\n",
    "                total_weight += weight\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            self.scores['overall'] = round(overall / total_weight * (total_weight), 2)\n",
    "        else:\n",
    "            self.scores['overall'] = 0\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_report(self):\n",
    "        \"\"\"\n",
    "        Get complete quality report.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'scores': self.scores,\n",
    "            'details': self.details,\n",
    "            'grade': self._score_to_grade(self.scores.get('overall', 0))\n",
    "        }\n",
    "    \n",
    "    def _score_to_grade(self, score):\n",
    "        \"\"\"Convert numeric score to letter grade.\"\"\"\n",
    "        if score >= 95:\n",
    "            return 'A+'\n",
    "        elif score >= 90:\n",
    "            return 'A'\n",
    "        elif score >= 85:\n",
    "            return 'B+'\n",
    "        elif score >= 80:\n",
    "            return 'B'\n",
    "        elif score >= 75:\n",
    "            return 'C+'\n",
    "        elif score >= 70:\n",
    "            return 'C'\n",
    "        elif score >= 60:\n",
    "            return 'D'\n",
    "        else:\n",
    "            return 'F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataQualityScorer` class calculates scores across four dimensions. Each dimension contributes equally by default, but weights can be customized based on business priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report - Weather Data\n",
      "==================================================\n",
      "\n",
      "Overall Grade: A+\n",
      "Overall Score: 100.0/100\n",
      "\n",
      "Dimension Scores:\n",
      "  Completeness    ████████████████████ 100.0%\n",
      "  Validity        ████████████████████ 100.0%\n",
      "  Uniqueness      ████████████████████ 100.0%\n",
      "  Consistency     ████████████████████ 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Score the weather data quality\n",
    "\n",
    "# Define validation rules\n",
    "validity_rules = {\n",
    "    'temperature_celsius': {'min': -90, 'max': 60},\n",
    "    'humidity': {'min': 0, 'max': 100},\n",
    "    'pressure_mb': {'min': 870, 'max': 1085},\n",
    "    'wind_kph': {'min': 0, 'max': 410}\n",
    "}\n",
    "\n",
    "# Define consistency rules\n",
    "consistency_rules = [\n",
    "    {\n",
    "        'name': 'temp_celsius_fahrenheit_match',\n",
    "        'check': lambda df: abs(df['temperature_fahrenheit'] - (df['temperature_celsius'] * 9/5 + 32)) < 1\n",
    "    },\n",
    "    {\n",
    "        'name': 'feels_like_reasonable',\n",
    "        'check': lambda df: abs(df['feels_like_celsius'] - df['temperature_celsius']) < 20\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run scoring\n",
    "scorer = DataQualityScorer(df_weather)\n",
    "\n",
    "quality_report = (\n",
    "    scorer\n",
    "    .score_completeness(required_columns=['country', 'temperature_celsius', 'humidity'])\n",
    "    .score_validity(validity_rules)\n",
    "    .score_uniqueness(key_columns=['country', 'location_name', 'last_updated'])\n",
    "    .score_consistency(consistency_rules)\n",
    "    .calculate_overall()\n",
    "    .get_report()\n",
    ")\n",
    "\n",
    "# Display report\n",
    "print(\"Data Quality Report - Weather Data\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall Grade: {quality_report['grade']}\")\n",
    "print(f\"Overall Score: {quality_report['scores']['overall']:.1f}/100\")\n",
    "\n",
    "print(\"\\nDimension Scores:\")\n",
    "for dimension in ['completeness', 'validity', 'uniqueness', 'consistency']:\n",
    "    if dimension in quality_report['scores']:\n",
    "        score = quality_report['scores'][dimension]\n",
    "        bar = '█' * int(score / 5) + '░' * (20 - int(score / 5))\n",
    "        print(f\"  {dimension.capitalize():15} {bar} {score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality report provides a clear visual summary. The bar chart makes it easy to identify which dimensions need the most attention.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Automated Quality Reports\n",
    "\n",
    "### Putting It All Together\n",
    "\n",
    "Let's create a comprehensive quality report that can be generated automatically for any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY REPORT: GlobalWeatherRepository\n",
      "======================================================================\n",
      "Generated: 2026-02-02 09:58:00\n",
      "\n",
      "DATASET OVERVIEW\n",
      "----------------------------------------\n",
      "Rows: 43,884\n",
      "Columns: 41\n",
      "Memory usage: 40.69 MB\n",
      "\n",
      "COLUMN TYPES\n",
      "----------------------------------------\n",
      "  float64: 23 columns\n",
      "  object: 11 columns\n",
      "  int64: 7 columns\n",
      "\n",
      "MISSING VALUES\n",
      "----------------------------------------\n",
      "  No missing values found!\n",
      "\n",
      "NUMERIC COLUMN STATISTICS\n",
      "----------------------------------------\n",
      "  latitude:\n",
      "    Min: -41.30, Max: 64.15\n",
      "    Mean: 19.14, Median: 17.25\n",
      "    Std: 24.48\n",
      "  longitude:\n",
      "    Min: -175.20, Max: 179.22\n",
      "    Mean: 22.14, Median: 23.32\n",
      "    Std: 65.81\n",
      "  last_updated_epoch:\n",
      "    Min: 1715849100.00, Max: 1735385400.00\n",
      "    Mean: 1725624383.47, Median: 1725710400.00\n",
      "    Std: 5694807.07\n",
      "  temperature_celsius:\n",
      "    Min: -24.20, Max: 49.20\n",
      "    Mean: 23.69, Median: 25.80\n",
      "    Std: 8.68\n",
      "  temperature_fahrenheit:\n",
      "    Min: -11.60, Max: 120.60\n",
      "    Mean: 74.65, Median: 78.50\n",
      "    Std: 15.63\n",
      "\n",
      "DUPLICATE ANALYSIS\n",
      "----------------------------------------\n",
      "  Exact duplicate rows: 0 (0.00%)\n",
      "\n",
      "QUALITY SCORES\n",
      "----------------------------------------\n",
      "  Completeness: 100.0%\n",
      "  Uniqueness: 100.0%\n",
      "  Overall: 100.0%\n",
      "\n",
      "======================================================================\n",
      "END OF REPORT\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def generate_quality_report(df, dataset_name, output_file=None):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive data quality report.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset to analyze\n",
    "    dataset_name : str\n",
    "        Name for the report\n",
    "    output_file : str\n",
    "        Optional path to save report\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Formatted report text\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    \n",
    "    def add_line(text=\"\"):\n",
    "        report_lines.append(text)\n",
    "    \n",
    "    # Header\n",
    "    add_line(\"=\" * 70)\n",
    "    add_line(f\"DATA QUALITY REPORT: {dataset_name}\")\n",
    "    add_line(\"=\" * 70)\n",
    "    add_line(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    add_line()\n",
    "    \n",
    "    # Basic Statistics\n",
    "    add_line(\"DATASET OVERVIEW\")\n",
    "    add_line(\"-\" * 40)\n",
    "    add_line(f\"Rows: {len(df):,}\")\n",
    "    add_line(f\"Columns: {len(df.columns)}\")\n",
    "    add_line(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "    add_line()\n",
    "    \n",
    "    # Column Types\n",
    "    add_line(\"COLUMN TYPES\")\n",
    "    add_line(\"-\" * 40)\n",
    "    type_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in type_counts.items():\n",
    "        add_line(f\"  {dtype}: {count} columns\")\n",
    "    add_line()\n",
    "    \n",
    "    # Missing Values\n",
    "    add_line(\"MISSING VALUES\")\n",
    "    add_line(\"-\" * 40)\n",
    "    missing = df.isnull().sum()\n",
    "    missing_cols = missing[missing > 0].sort_values(ascending=False)\n",
    "    if len(missing_cols) > 0:\n",
    "        for col in missing_cols.head(10).index:\n",
    "            pct = missing_cols[col] / len(df) * 100\n",
    "            add_line(f\"  {col}: {missing_cols[col]:,} ({pct:.1f}%)\")\n",
    "        if len(missing_cols) > 10:\n",
    "            add_line(f\"  ... and {len(missing_cols) - 10} more columns with missing values\")\n",
    "    else:\n",
    "        add_line(\"  No missing values found!\")\n",
    "    add_line()\n",
    "    \n",
    "    # Numeric Column Statistics\n",
    "    add_line(\"NUMERIC COLUMN STATISTICS\")\n",
    "    add_line(\"-\" * 40)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns[:5]  # First 5\n",
    "    for col in numeric_cols:\n",
    "        add_line(f\"  {col}:\")\n",
    "        add_line(f\"    Min: {df[col].min():.2f}, Max: {df[col].max():.2f}\")\n",
    "        add_line(f\"    Mean: {df[col].mean():.2f}, Median: {df[col].median():.2f}\")\n",
    "        add_line(f\"    Std: {df[col].std():.2f}\")\n",
    "    add_line()\n",
    "    \n",
    "    # Duplicate Analysis\n",
    "    add_line(\"DUPLICATE ANALYSIS\")\n",
    "    add_line(\"-\" * 40)\n",
    "    exact_dups = df.duplicated().sum()\n",
    "    add_line(f\"  Exact duplicate rows: {exact_dups:,} ({exact_dups/len(df)*100:.2f}%)\")\n",
    "    add_line()\n",
    "    \n",
    "    # Quality Score Summary\n",
    "    add_line(\"QUALITY SCORES\")\n",
    "    add_line(\"-\" * 40)\n",
    "    \n",
    "    # Calculate scores\n",
    "    completeness = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "    uniqueness = (1 - exact_dups / len(df)) * 100\n",
    "    \n",
    "    add_line(f\"  Completeness: {completeness:.1f}%\")\n",
    "    add_line(f\"  Uniqueness: {uniqueness:.1f}%\")\n",
    "    add_line(f\"  Overall: {(completeness + uniqueness) / 2:.1f}%\")\n",
    "    add_line()\n",
    "    \n",
    "    # Footer\n",
    "    add_line(\"=\" * 70)\n",
    "    add_line(\"END OF REPORT\")\n",
    "    add_line(\"=\" * 70)\n",
    "    \n",
    "    report_text = \"\\n\".join(report_lines)\n",
    "    \n",
    "    # Save if output file specified\n",
    "    if output_file:\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(report_text)\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "\n",
    "# Generate report for weather data\n",
    "report = generate_quality_report(df_weather, 'GlobalWeatherRepository')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automated report provides a comprehensive overview that can be generated for any dataset. This is valuable for:\n",
    "- **Initial data exploration**: Quick understanding of data quality\n",
    "- **Pipeline monitoring**: Run after each ETL to track quality\n",
    "- **Documentation**: Archive reports for audit trails\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. Outlier Detection\n",
    "- IQR method is robust (doesn't assume normality)\n",
    "- Z-score method works well for normal distributions\n",
    "- Domain rules are essential for physical constraints\n",
    "\n",
    "### 2. Missing Values\n",
    "- Understand the mechanism (MCAR, MAR, MNAR)\n",
    "- Choose imputation strategy based on data type\n",
    "- Document all handling decisions\n",
    "\n",
    "### 3. Validation Rules\n",
    "- Schema validation: required columns, types\n",
    "- Range validation: min/max bounds\n",
    "- Uniqueness: key constraints\n",
    "\n",
    "### 4. Referential Integrity\n",
    "- Check foreign key relationships\n",
    "- Identify orphan records\n",
    "- Verify cross-table consistency\n",
    "\n",
    "### 5. Quality Scoring\n",
    "- Score across multiple dimensions\n",
    "- Weight by business importance\n",
    "- Track trends over time\n",
    "\n",
    "### 6. Automation\n",
    "- Build reusable validation classes\n",
    "- Generate reports automatically\n",
    "- Integrate into ETL pipelines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Books\n",
    "- McKinney, W. (2022). *Python for Data Analysis* (3rd ed.). O'Reilly Media.\n",
    "  - Chapter 7: Data Cleaning and Preparation\n",
    "- Maydanchik, A. (2007). *Data Quality Assessment*. Technics Publications.\n",
    "- Dasu, T., & Johnson, T. (2003). *Exploratory Data Mining and Data Cleaning*. Wiley.\n",
    "\n",
    "### Documentation\n",
    "- [pandas Missing Data](https://pandas.pydata.org/docs/user_guide/missing_data.html)\n",
    "- [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html)\n",
    "\n",
    "### Academic Papers\n",
    "- Rubin, D. B. (1976). \"Inference and Missing Data.\" *Biometrika*, 63(3), 581-592.\n",
    "- Tukey, J. W. (1977). *Exploratory Data Analysis*. Addison-Wesley.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "### Exercise 1: Food Data Outlier Analysis\n",
    "Apply IQR and Z-score outlier detection to the Food Nutrition dataset. Compare the results for caloric value and protein content.\n",
    "\n",
    "### Exercise 2: Custom Validator\n",
    "Extend the `DataValidator` class with a `check_pattern` method that validates string columns against a regex pattern (e.g., email format, phone numbers).\n",
    "\n",
    "### Exercise 3: Missing Value Imputation\n",
    "Implement a group-based imputation strategy that fills missing values with the group mean (e.g., fill missing temperature with average for that country).\n",
    "\n",
    "### Exercise 4: Quality Dashboard\n",
    "Create a function that outputs the quality report as HTML with color-coded scores (green for good, red for poor).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Class: Visualization I\n",
    "\n",
    "In Lecture 11, we will cover:\n",
    "- Matplotlib fundamentals\n",
    "- Plotly interactive charts\n",
    "- Time series visualization\n",
    "- Storytelling with figures\n",
    "- Accessibility and color choices\n",
    "\n",
    "We will visualize our cleaned weather and climate data to communicate insights effectively.\n",
    "\n",
    "---\n",
    "\n",
    "*End of Lecture 10*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
